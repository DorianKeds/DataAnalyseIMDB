# -*- coding: utf-8 -*-
"""IMBDScrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/164Z65apgsC_oAmBkGDavv8aoB_sM9IMi
"""



import pandas as pd
from bs4 import BeautifulSoup
import requests
import time

# |----------- scrap_url function ---------------|
# |----------------- Definition -----------------|
# |                                              |
# |                                              |
# |------------------- author -------------------|
# | Dorian KEDDAR - 03/05/2021                   |
# |----------------------------------------------|

def scrap_url():
  urls = []
  ur = []
  page_url = []
  url_film = []
  url_a = []
  url_u = []
  n = range(1,10001, 50)
  start_time = time.time()
  #récupère les 9951 premiers films
  for i in n:
    url = 'https://www.imdb.com/search/title/?at=0&num_votes=5000,&sort=user_rating,desc&start=' + str(i) + '&title_type=feature' 
    urls.append(url)
  #récuperer les dernières urls qui change de start à partir de 9951
  html = requests.get(urls[199]).text
  soup = BeautifulSoup(html, 'html.parser')
  url = soup.find('a', attrs = {'class':'lister-page-next next-page'})['href']
  u = 'https://www.imdb.com' + url
  while True:
    html = requests.get(u).text
    soup = BeautifulSoup(html,'html.parser')
    url = soup.find('a', attrs = {'class':'lister-page-next next-page'})
    try:
      url = url['href']
      u = 'https://www.imdb.com' + url
      ur.append(u)
    except:
      break
  page_url = urls + ur
  #récuperer les URL de chacun des films
  for i in range(len(page_url)):
    html = requests.get(page_url[i]).text
    soup = BeautifulSoup(html, 'html.parser')
    h3 = soup.find_all('h3', attrs = {'class':'lister-item-header'})
    for i in range(len(h3)):
      a = h3[i].find('a')['href']
      url_a.append(a)
  for i in range(len(url_a)):
      u = 'https://www.imdb.com/' + url_a[i]
      url_u.append(u)
  print("--- %s seconds ---" % (time.time() - start_time))
  return url_u


# |----------- scrap_info function --------------|
# |----------------- Definition -----------------|
# |                                              |
# |                                              |
# |------------------- author -------------------|
# | Dorian KEDDAR - 03/05/2021                   |
# |----------------------------------------------|
def scrap_info():
  sc = []
  ac = []
  ty = []
  f = []
  info = []
  url = scrap_url()
  start_time = time.time()
  for i in range(0,100):
    html = requests.get(url[i]).text
    soup = BeautifulSoup(html, 'html.parser')
    box_div = soup.find_all('div', attrs = {'class':'txt-block'})
    #Nom du film
    try:
      name = soup.find('div', attrs = {'class':'title_wrapper'}).find('h1').contents[0].strip()
    except:
      name = 'XXX'
    #Année
    try:
      year = soup.find('span', attrs = {'id':'titleYear'}).find('a').contents[0].strip()
    except:
      year = 'XXX'
    #Note du film
    try:
      note = soup.find('span', attrs = {'itemprop':'ratingValue'}).contents[0].strip()
    except:
      note = 'XXX'
    #Score
    try:
      score = soup.find('div', attrs = {'class':'metacriticScore score_favorable titleReviewBarSubItem'}).find('span').contents[0].strip()
    except:
      score = 'XXX'
    #Nombre de vote
    try:
      ratingCount = soup.find('span', attrs = {'itemprop':'ratingCount'}).contents[0].strip()
    except:
      ratingCount = 'XXX'
    #Directeur
    try:
      dir = soup.find_all('div', attrs = {'class':'credit_summary_item'})[0].find('a').contents[0].strip()
    except:
      dir = 'XXX'
    #Scénariste
    try:
      sce = soup.find_all('div', attrs = {'class':'credit_summary_item'})[1].find_all('a')
      for i in range(len(sce)):
        s = sce[i].contents[0].strip()
        sc.append(s)
    except:
      sc = 'XXX'
    #Star
    try:
      act = soup.find_all('div', attrs = {'class':'credit_summary_item'})[2].find_all('a')
      for i in range(len(act)):
        a = act[i].contents[0].strip()
        ac.append(a)
    except:
      ac = 'XXX'
    #Duré du film
    try:
      duration = dursoup.find('time').contents[0].strip()
    except:
      duration = 'XXX'
    #Type de film
    try:
      film_type = soup.find('div', attrs = {'class':'subtext'}).find('a').contents[0]
    except:
      film_type = 'XXX'
    #Date de sortie
    try:
      date = soup.find('div', attrs = {'class':'subtext'}).find('a', attrs = {'title':'See more release dates'}).contents[0].strip()
    except:
      date = 'XXX'
    #Pays de sortie
    try:
      countrie = soup.select('a[href*=country_of_origin]')
    except:
      countrie = 'XXX'
    #Lieu de tournage
    try:
      location = soup.select('a[href*=/search/title?locations]')
    except:
      location = 'XXX'
    #Nombre de review
    try:
      review = soup.select('a[href*=reviews?ref]')
    except:
      review = 'XXX'
    #Filmographie
    try:
      filmo = soup.find_all('div', attrs = {'class':'rec_item'})
      for i in range(len(filmo)):
        fil = filmo[i].find_all('img')
        for i in range(len(fil)):
          fi = fil[i]['title']
          f.append(fi)
    except:
      f = 'XXX'
    #Budget
    try:
      budget = box_div[13].text[0:].strip()
    except:
      budget = 'XXX'
    #Revenu généré le premier week end au USA (Opening Weekend USA)
    try:
      open_week_usa = box_div[14].text[0:].strip()
    except:
      open_week_usa = 'XXX'
    #Revenue généré aux USA (Gross USA)
    try:
      gross_usa = box_div[15].text[0:].strip()
    except:
      gross_usa = 'XXX'
    #Revenue généré dans le monde(Cumulative Worldwide Gross)
    try:
      cumul_gross = box_div[16].text[0:].strip()
    except:
      cumul_gross = 'XXX'
    #Runtime
    try:
      runtime = soup.find_all('time', attrs = {'datetime':'PT142M'})[1].contents[0].strip()
    except:
      runtime = 'XXX'
    #Sound Mix
    try:
      sound = soup.select('a[href*=/search/title?sound_mixes]')
    except:
      sound = 'XXX'
    #Color
    try:
      color = soup.select('a[href*=/search/title?color]')
    except:
      color = 'XXX'
    #Aspect ratio
    try:
      r = box_div[22].text[15:].strip()
    except:
      r = 'XXX'
    info.append((name,year, note, score, ratingCount, dir, sc, ac, duration, film_type, date, countrie, location, review, f, budget, open_week_usa, gross_usa, cumul_gross, runtime, sound, color, r))
    df = pd.DataFrame(info, columns = ['Film_Name', 'Year', 'Note', 'Score','RatingCount', 'Director', 'Writters', 'Actors', 
                                     'Duration', 'Film_Type', 'Release_Date', 'Countrie_Origin', 'Location', 'Review', 
                                     'Fimography', 'Budget', 'Open_Week_USA_Gross', 'Gross_USA', 'Cumul_Gross_WW', 'Runtime', 'Sound', 'Color', 'Ratio'])
  print("--- %s seconds ---" % (time.time() - start_time))
  return df
# |----------- scrap_info function --------------|
# |----------------- Definition -----------------|
# |                                              |
# |                                              |
# |------------------- author -------------------|
# | Dorian KEDDAR - 03/05/2021                   |
# |----------------------------------------------|
def csv_extract():
  df = scrap_info()
  df.to_csv('imdb_dataset.csv')